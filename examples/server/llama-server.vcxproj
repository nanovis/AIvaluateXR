<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" ToolsVersion="17.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <PropertyGroup>
    <PreferredToolArchitecture>x64</PreferredToolArchitecture>
  </PropertyGroup>
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="MinSizeRel|x64">
      <Configuration>MinSizeRel</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="RelWithDebInfo|x64">
      <Configuration>RelWithDebInfo</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
  </ItemGroup>
  <PropertyGroup Label="Globals">
    <ProjectGuid>{101F92EA-B9A8-3609-BCA1-68A0BD514058}</ProjectGuid>
    <Keyword>Win32Proj</Keyword>
    <WindowsTargetPlatformVersion>10.0.22621.0</WindowsTargetPlatformVersion>
    <Platform>x64</Platform>
    <ProjectName>llama-server</ProjectName>
    <VCProjectUpgraderObjectName>NoUpgrade</VCProjectUpgraderObjectName>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <CharacterSet>MultiByte</CharacterSet>
    <PlatformToolset>v143</PlatformToolset>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <CharacterSet>MultiByte</CharacterSet>
    <PlatformToolset>v143</PlatformToolset>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <CharacterSet>MultiByte</CharacterSet>
    <PlatformToolset>v143</PlatformToolset>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <CharacterSet>MultiByte</CharacterSet>
    <PlatformToolset>v143</PlatformToolset>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
    <Import Project="$(VCTargetsPath)\BuildCustomizations\CUDA 12.6.props" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <PropertyGroup Label="UserMacros" />
  <PropertyGroup>
    <_ProjectFileVersion>10.0.20506.1</_ProjectFileVersion>
    <OutDir Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\bin\Debug\</OutDir>
    <IntDir Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">llama-server.dir\Debug\</IntDir>
    <TargetName Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">llama-server</TargetName>
    <TargetExt Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">.exe</TargetExt>
    <LinkIncremental Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">true</LinkIncremental>
    <GenerateManifest Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">true</GenerateManifest>
    <OutDir Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\bin\Release\</OutDir>
    <IntDir Condition="'$(Configuration)|$(Platform)'=='Release|x64'">llama-server.dir\Release\</IntDir>
    <TargetName Condition="'$(Configuration)|$(Platform)'=='Release|x64'">llama-server</TargetName>
    <TargetExt Condition="'$(Configuration)|$(Platform)'=='Release|x64'">.exe</TargetExt>
    <LinkIncremental Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkIncremental>
    <GenerateManifest Condition="'$(Configuration)|$(Platform)'=='Release|x64'">true</GenerateManifest>
    <OutDir Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\bin\MinSizeRel\</OutDir>
    <IntDir Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">llama-server.dir\MinSizeRel\</IntDir>
    <TargetName Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">llama-server</TargetName>
    <TargetExt Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">.exe</TargetExt>
    <LinkIncremental Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkIncremental>
    <GenerateManifest Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">true</GenerateManifest>
    <OutDir Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\bin\RelWithDebInfo\</OutDir>
    <IntDir Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">llama-server.dir\RelWithDebInfo\</IntDir>
    <TargetName Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">llama-server</TargetName>
    <TargetExt Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">.exe</TargetExt>
    <LinkIncremental Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">true</LinkIncremental>
    <GenerateManifest Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">true</GenerateManifest>
  </PropertyGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <AssemblerListingLocation>$(IntDir)</AssemblerListingLocation>
      <BasicRuntimeChecks>EnableFastChecks</BasicRuntimeChecks>
      <DebugInformationFormat>ProgramDatabase</DebugInformationFormat>
      <ExceptionHandling>Sync</ExceptionHandling>
      <InlineFunctionExpansion>Disabled</InlineFunctionExpansion>
      <MinimalRebuild></MinimalRebuild>
      <Optimization>Disabled</Optimization>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <RuntimeLibrary>MultiThreadedDebugDLL</RuntimeLibrary>
      <RuntimeTypeInfo>true</RuntimeTypeInfo>
      <SupportJustMyCode></SupportJustMyCode>
      <UseFullPaths>false</UseFullPaths>
      <WarningLevel>Level3</WarningLevel>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;SERVER_VERBOSE=1;_CRT_SECURE_NO_WARNINGS;GGML_USE_CUDA;CMAKE_INTDIR="Debug"</PreprocessorDefinitions>
      <ObjectFileName>$(IntDir)</ObjectFileName>
      <ScanSourceForModuleDependencies>false</ScanSourceForModuleDependencies>
    </ClCompile>
    <ResourceCompile>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_DEBUG;_WINDOWS;SERVER_VERBOSE=1;_CRT_SECURE_NO_WARNINGS;GGML_USE_CUDA;CMAKE_INTDIR=\"Debug\"</PreprocessorDefinitions>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
    </ResourceCompile>
    <Midl>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <OutputDirectory>$(ProjectDir)/$(IntDir)</OutputDirectory>
      <HeaderFileName>%(Filename).h</HeaderFileName>
      <TypeLibraryName>%(Filename).tlb</TypeLibraryName>
      <InterfaceIdentifierFileName>%(Filename)_i.c</InterfaceIdentifierFileName>
      <ProxyFileName>%(Filename)_p.c</ProxyFileName>
    </Midl>
    <Link>
      <AdditionalDependencies>..\..\common\Debug\common.lib;ws2_32.lib;..\..\src\Debug\llama.lib;..\..\ggml\src\Debug\ggml.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>
      <AdditionalLibraryDirectories>%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>
      <AdditionalOptions>%(AdditionalOptions) /machine:x64</AdditionalOptions>
      <GenerateDebugInformation>true</GenerateDebugInformation>
      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>
      <ImportLibrary>D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/Debug/llama-server.lib</ImportLibrary>
      <ProgramDataBaseFile>D:/git3/MagicLeap/LLM/dd/llama.cpp/build/bin/Debug/llama-server.pdb</ProgramDataBaseFile>
      <SubSystem>Console</SubSystem>
    </Link>
    <ProjectReference>
      <LinkLibraryDependencies>false</LinkLibraryDependencies>
    </ProjectReference>
    <CudaLink>
      <AdditionalOptions></AdditionalOptions>
      <PerformDeviceLink>false</PerformDeviceLink>
    </CudaLink>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <AssemblerListingLocation>$(IntDir)</AssemblerListingLocation>
      <BasicRuntimeChecks>Default</BasicRuntimeChecks>
      <ExceptionHandling>Sync</ExceptionHandling>
      <InlineFunctionExpansion>AnySuitable</InlineFunctionExpansion>
      <MinimalRebuild></MinimalRebuild>
      <Optimization>MaxSpeed</Optimization>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <RuntimeLibrary>MultiThreadedDLL</RuntimeLibrary>
      <RuntimeTypeInfo>true</RuntimeTypeInfo>
      <SupportJustMyCode></SupportJustMyCode>
      <UseFullPaths>false</UseFullPaths>
      <WarningLevel>Level3</WarningLevel>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;NDEBUG;SERVER_VERBOSE=1;_CRT_SECURE_NO_WARNINGS;GGML_USE_CUDA;CMAKE_INTDIR="Release"</PreprocessorDefinitions>
      <ObjectFileName>$(IntDir)</ObjectFileName>
      <DebugInformationFormat>
      </DebugInformationFormat>
      <ScanSourceForModuleDependencies>false</ScanSourceForModuleDependencies>
    </ClCompile>
    <ResourceCompile>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;NDEBUG;SERVER_VERBOSE=1;_CRT_SECURE_NO_WARNINGS;GGML_USE_CUDA;CMAKE_INTDIR=\"Release\"</PreprocessorDefinitions>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
    </ResourceCompile>
    <Midl>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <OutputDirectory>$(ProjectDir)/$(IntDir)</OutputDirectory>
      <HeaderFileName>%(Filename).h</HeaderFileName>
      <TypeLibraryName>%(Filename).tlb</TypeLibraryName>
      <InterfaceIdentifierFileName>%(Filename)_i.c</InterfaceIdentifierFileName>
      <ProxyFileName>%(Filename)_p.c</ProxyFileName>
    </Midl>
    <Link>
      <AdditionalDependencies>..\..\common\Release\common.lib;ws2_32.lib;..\..\src\Release\llama.lib;..\..\ggml\src\Release\ggml.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>
      <AdditionalLibraryDirectories>%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>
      <AdditionalOptions>%(AdditionalOptions) /machine:x64</AdditionalOptions>
      <GenerateDebugInformation>false</GenerateDebugInformation>
      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>
      <ImportLibrary>D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/Release/llama-server.lib</ImportLibrary>
      <ProgramDataBaseFile>D:/git3/MagicLeap/LLM/dd/llama.cpp/build/bin/Release/llama-server.pdb</ProgramDataBaseFile>
      <SubSystem>Console</SubSystem>
    </Link>
    <ProjectReference>
      <LinkLibraryDependencies>false</LinkLibraryDependencies>
    </ProjectReference>
    <CudaLink>
      <AdditionalOptions></AdditionalOptions>
      <PerformDeviceLink>false</PerformDeviceLink>
    </CudaLink>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">
    <ClCompile>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <AssemblerListingLocation>$(IntDir)</AssemblerListingLocation>
      <BasicRuntimeChecks>Default</BasicRuntimeChecks>
      <ExceptionHandling>Sync</ExceptionHandling>
      <InlineFunctionExpansion>OnlyExplicitInline</InlineFunctionExpansion>
      <MinimalRebuild></MinimalRebuild>
      <Optimization>MinSpace</Optimization>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <RuntimeLibrary>MultiThreadedDLL</RuntimeLibrary>
      <RuntimeTypeInfo>true</RuntimeTypeInfo>
      <SupportJustMyCode></SupportJustMyCode>
      <UseFullPaths>false</UseFullPaths>
      <WarningLevel>Level3</WarningLevel>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;NDEBUG;SERVER_VERBOSE=1;_CRT_SECURE_NO_WARNINGS;GGML_USE_CUDA;CMAKE_INTDIR="MinSizeRel"</PreprocessorDefinitions>
      <ObjectFileName>$(IntDir)</ObjectFileName>
      <DebugInformationFormat>
      </DebugInformationFormat>
      <ScanSourceForModuleDependencies>false</ScanSourceForModuleDependencies>
    </ClCompile>
    <ResourceCompile>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;NDEBUG;SERVER_VERBOSE=1;_CRT_SECURE_NO_WARNINGS;GGML_USE_CUDA;CMAKE_INTDIR=\"MinSizeRel\"</PreprocessorDefinitions>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
    </ResourceCompile>
    <Midl>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <OutputDirectory>$(ProjectDir)/$(IntDir)</OutputDirectory>
      <HeaderFileName>%(Filename).h</HeaderFileName>
      <TypeLibraryName>%(Filename).tlb</TypeLibraryName>
      <InterfaceIdentifierFileName>%(Filename)_i.c</InterfaceIdentifierFileName>
      <ProxyFileName>%(Filename)_p.c</ProxyFileName>
    </Midl>
    <Link>
      <AdditionalDependencies>..\..\common\MinSizeRel\common.lib;ws2_32.lib;..\..\src\MinSizeRel\llama.lib;..\..\ggml\src\MinSizeRel\ggml.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>
      <AdditionalLibraryDirectories>%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>
      <AdditionalOptions>%(AdditionalOptions) /machine:x64</AdditionalOptions>
      <GenerateDebugInformation>false</GenerateDebugInformation>
      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>
      <ImportLibrary>D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/MinSizeRel/llama-server.lib</ImportLibrary>
      <ProgramDataBaseFile>D:/git3/MagicLeap/LLM/dd/llama.cpp/build/bin/MinSizeRel/llama-server.pdb</ProgramDataBaseFile>
      <SubSystem>Console</SubSystem>
    </Link>
    <ProjectReference>
      <LinkLibraryDependencies>false</LinkLibraryDependencies>
    </ProjectReference>
    <CudaLink>
      <AdditionalOptions></AdditionalOptions>
      <PerformDeviceLink>false</PerformDeviceLink>
    </CudaLink>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">
    <ClCompile>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <AssemblerListingLocation>$(IntDir)</AssemblerListingLocation>
      <BasicRuntimeChecks>Default</BasicRuntimeChecks>
      <DebugInformationFormat>ProgramDatabase</DebugInformationFormat>
      <ExceptionHandling>Sync</ExceptionHandling>
      <InlineFunctionExpansion>OnlyExplicitInline</InlineFunctionExpansion>
      <MinimalRebuild></MinimalRebuild>
      <Optimization>MaxSpeed</Optimization>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <RuntimeLibrary>MultiThreadedDLL</RuntimeLibrary>
      <RuntimeTypeInfo>true</RuntimeTypeInfo>
      <SupportJustMyCode></SupportJustMyCode>
      <UseFullPaths>false</UseFullPaths>
      <WarningLevel>Level3</WarningLevel>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;NDEBUG;SERVER_VERBOSE=1;_CRT_SECURE_NO_WARNINGS;GGML_USE_CUDA;CMAKE_INTDIR="RelWithDebInfo"</PreprocessorDefinitions>
      <ObjectFileName>$(IntDir)</ObjectFileName>
      <ScanSourceForModuleDependencies>false</ScanSourceForModuleDependencies>
    </ClCompile>
    <ResourceCompile>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;NDEBUG;SERVER_VERBOSE=1;_CRT_SECURE_NO_WARNINGS;GGML_USE_CUDA;CMAKE_INTDIR=\"RelWithDebInfo\"</PreprocessorDefinitions>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
    </ResourceCompile>
    <Midl>
      <AdditionalIncludeDirectories>D:\git3\MagicLeap\LLM\dd\llama.cpp\examples;D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server;D:\git3\MagicLeap\LLM\dd\llama.cpp\common\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\.;D:\git3\MagicLeap\LLM\dd\llama.cpp\src\..\include;D:\git3\MagicLeap\LLM\dd\llama.cpp\ggml\src\..\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <OutputDirectory>$(ProjectDir)/$(IntDir)</OutputDirectory>
      <HeaderFileName>%(Filename).h</HeaderFileName>
      <TypeLibraryName>%(Filename).tlb</TypeLibraryName>
      <InterfaceIdentifierFileName>%(Filename)_i.c</InterfaceIdentifierFileName>
      <ProxyFileName>%(Filename)_p.c</ProxyFileName>
    </Midl>
    <Link>
      <AdditionalDependencies>..\..\common\RelWithDebInfo\common.lib;ws2_32.lib;..\..\src\RelWithDebInfo\llama.lib;..\..\ggml\src\RelWithDebInfo\ggml.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>
      <AdditionalLibraryDirectories>%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>
      <AdditionalOptions>%(AdditionalOptions) /machine:x64</AdditionalOptions>
      <GenerateDebugInformation>true</GenerateDebugInformation>
      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>
      <ImportLibrary>D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/RelWithDebInfo/llama-server.lib</ImportLibrary>
      <ProgramDataBaseFile>D:/git3/MagicLeap/LLM/dd/llama.cpp/build/bin/RelWithDebInfo/llama-server.pdb</ProgramDataBaseFile>
      <SubSystem>Console</SubSystem>
    </Link>
    <ProjectReference>
      <LinkLibraryDependencies>false</LinkLibraryDependencies>
    </ProjectReference>
    <CudaLink>
      <AdditionalOptions></AdditionalOptions>
      <PerformDeviceLink>false</PerformDeviceLink>
    </CudaLink>
  </ItemDefinitionGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\colorthemes.css.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating colorthemes.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/colorthemes.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/colorthemes.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\colorthemes.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\colorthemes.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating colorthemes.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/colorthemes.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/colorthemes.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\colorthemes.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\colorthemes.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating colorthemes.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/colorthemes.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/colorthemes.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\colorthemes.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\colorthemes.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating colorthemes.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/colorthemes.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/colorthemes.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\colorthemes.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\colorthemes.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\style.css.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating style.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/style.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/style.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\style.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\style.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating style.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/style.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/style.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\style.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\style.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating style.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/style.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/style.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\style.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\style.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating style.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/style.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/style.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\style.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\style.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\theme-beeninorder.css.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating theme-beeninorder.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-beeninorder.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-beeninorder.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-beeninorder.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-beeninorder.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating theme-beeninorder.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-beeninorder.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-beeninorder.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-beeninorder.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-beeninorder.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating theme-beeninorder.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-beeninorder.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-beeninorder.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-beeninorder.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-beeninorder.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating theme-beeninorder.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-beeninorder.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-beeninorder.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-beeninorder.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-beeninorder.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\theme-ketivah.css.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating theme-ketivah.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-ketivah.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-ketivah.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-ketivah.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-ketivah.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating theme-ketivah.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-ketivah.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-ketivah.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-ketivah.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-ketivah.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating theme-ketivah.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-ketivah.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-ketivah.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-ketivah.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-ketivah.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating theme-ketivah.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-ketivah.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-ketivah.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-ketivah.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-ketivah.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\theme-mangotango.css.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating theme-mangotango.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-mangotango.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-mangotango.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-mangotango.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-mangotango.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating theme-mangotango.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-mangotango.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-mangotango.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-mangotango.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-mangotango.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating theme-mangotango.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-mangotango.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-mangotango.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-mangotango.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-mangotango.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating theme-mangotango.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-mangotango.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-mangotango.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-mangotango.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-mangotango.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\theme-playground.css.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating theme-playground.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-playground.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-playground.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-playground.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-playground.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating theme-playground.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-playground.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-playground.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-playground.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-playground.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating theme-playground.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-playground.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-playground.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-playground.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-playground.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating theme-playground.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-playground.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-playground.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-playground.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-playground.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\theme-polarnight.css.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating theme-polarnight.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-polarnight.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-polarnight.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-polarnight.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-polarnight.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating theme-polarnight.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-polarnight.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-polarnight.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-polarnight.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-polarnight.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating theme-polarnight.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-polarnight.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-polarnight.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-polarnight.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-polarnight.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating theme-polarnight.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-polarnight.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-polarnight.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-polarnight.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-polarnight.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\theme-snowstorm.css.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating theme-snowstorm.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-snowstorm.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-snowstorm.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-snowstorm.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-snowstorm.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating theme-snowstorm.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-snowstorm.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-snowstorm.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-snowstorm.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-snowstorm.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating theme-snowstorm.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-snowstorm.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-snowstorm.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-snowstorm.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-snowstorm.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating theme-snowstorm.css.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/theme-snowstorm.css -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/theme-snowstorm.css.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\theme-snowstorm.css;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-snowstorm.css.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\index.html.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating index.html.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index.html -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index.html.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index.html;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index.html.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating index.html.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index.html -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index.html.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index.html;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index.html.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating index.html.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index.html -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index.html.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index.html;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index.html.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating index.html.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index.html -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index.html.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index.html;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index.html.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\index-new.html.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating index-new.html.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index-new.html -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index-new.html.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index-new.html;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index-new.html.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating index-new.html.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index-new.html -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index-new.html.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index-new.html;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index-new.html.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating index-new.html.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index-new.html -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index-new.html.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index-new.html;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index-new.html.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating index-new.html.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index-new.html -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index-new.html.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index-new.html;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index-new.html.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\index.js.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating index.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating index.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating index.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating index.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/index.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/index.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\index.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\completion.js.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating completion.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/completion.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/completion.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\completion.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\completion.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating completion.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/completion.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/completion.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\completion.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\completion.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating completion.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/completion.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/completion.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\completion.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\completion.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating completion.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/completion.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/completion.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\completion.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\completion.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\system-prompts.js.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating system-prompts.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/system-prompts.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/system-prompts.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\system-prompts.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\system-prompts.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating system-prompts.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/system-prompts.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/system-prompts.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\system-prompts.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\system-prompts.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating system-prompts.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/system-prompts.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/system-prompts.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\system-prompts.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\system-prompts.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating system-prompts.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/system-prompts.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/system-prompts.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\system-prompts.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\system-prompts.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\prompt-formats.js.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating prompt-formats.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/prompt-formats.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/prompt-formats.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\prompt-formats.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\prompt-formats.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating prompt-formats.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/prompt-formats.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/prompt-formats.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\prompt-formats.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\prompt-formats.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating prompt-formats.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/prompt-formats.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/prompt-formats.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\prompt-formats.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\prompt-formats.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating prompt-formats.js.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/prompt-formats.js -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/prompt-formats.js.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\prompt-formats.js;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\prompt-formats.js.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\CMakeFiles\75034a1665565c907c54cf06c1b756a2\json-schema-to-grammar.mjs.hpp.rule">
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Generating json-schema-to-grammar.mjs.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/json-schema-to-grammar.mjs -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/json-schema-to-grammar.mjs.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\json-schema-to-grammar.mjs;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\json-schema-to-grammar.mjs.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Generating json-schema-to-grammar.mjs.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/json-schema-to-grammar.mjs -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/json-schema-to-grammar.mjs.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\json-schema-to-grammar.mjs;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\json-schema-to-grammar.mjs.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Generating json-schema-to-grammar.mjs.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/json-schema-to-grammar.mjs -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/json-schema-to-grammar.mjs.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\json-schema-to-grammar.mjs;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\json-schema-to-grammar.mjs.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Generating json-schema-to-grammar.mjs.hpp</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -DINPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/public/json-schema-to-grammar.mjs -DOUTPUT=D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/json-schema-to-grammar.mjs.hpp -P D:/git3/MagicLeap/LLM/dd/llama.cpp/scripts/xxd.cmake
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\public\json-schema-to-grammar.mjs;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\json-schema-to-grammar.mjs.hpp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <CustomBuild Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\CMakeLists.txt">
      <UseUtf8Encoding>Always</UseUtf8Encoding>
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Building Custom Rule D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/CMakeLists.txt</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -SD:/git3/MagicLeap/LLM/dd/llama.cpp -BD:/git3/MagicLeap/LLM/dd/llama.cpp/build --check-stamp-file D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/CMakeFiles/generate.stamp
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\CMakeFiles\generate.stamp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Building Custom Rule D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/CMakeLists.txt</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -SD:/git3/MagicLeap/LLM/dd/llama.cpp -BD:/git3/MagicLeap/LLM/dd/llama.cpp/build --check-stamp-file D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/CMakeFiles/generate.stamp
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\CMakeFiles\generate.stamp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Building Custom Rule D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/CMakeLists.txt</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -SD:/git3/MagicLeap/LLM/dd/llama.cpp -BD:/git3/MagicLeap/LLM/dd/llama.cpp/build --check-stamp-file D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/CMakeFiles/generate.stamp
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\CMakeFiles\generate.stamp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Building Custom Rule D:/git3/MagicLeap/LLM/dd/llama.cpp/examples/server/CMakeLists.txt</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" -SD:/git3/MagicLeap/LLM/dd/llama.cpp -BD:/git3/MagicLeap/LLM/dd/llama.cpp/build --check-stamp-file D:/git3/MagicLeap/LLM/dd/llama.cpp/build/examples/server/CMakeFiles/generate.stamp
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\CMakeFiles\generate.stamp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\server.cpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\utils.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\examples\server\httplib.h" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\colorthemes.css.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\style.css.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-beeninorder.css.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-ketivah.css.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-mangotango.css.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-playground.css.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-polarnight.css.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\theme-snowstorm.css.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index.html.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index-new.html.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\index.js.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\completion.js.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\system-prompts.js.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\prompt-formats.js.hpp" />
    <ClInclude Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\examples\server\json-schema-to-grammar.mjs.hpp" />
  </ItemGroup>
  <ItemGroup>
    <ProjectReference Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\ZERO_CHECK.vcxproj">
      <Project>{40E6D849-97E9-370D-AE47-84E67A99DA1C}</Project>
      <Name>ZERO_CHECK</Name>
      <ReferenceOutputAssembly>false</ReferenceOutputAssembly>
      <CopyToOutputDirectory>Never</CopyToOutputDirectory>
    </ProjectReference>
    <ProjectReference Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\common\build_info.vcxproj">
      <Project>{36AADA0D-9A97-3E82-9E89-FAE0E2B2B9EE}</Project>
      <Name>build_info</Name>
      <ReferenceOutputAssembly>false</ReferenceOutputAssembly>
      <CopyToOutputDirectory>Never</CopyToOutputDirectory>
    </ProjectReference>
    <ProjectReference Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\common\common.vcxproj">
      <Project>{F1F35CDA-1C40-3CF0-8E4E-A032F41C8675}</Project>
      <Name>common</Name>
    </ProjectReference>
    <ProjectReference Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\ggml\src\ggml.vcxproj">
      <Project>{C1838238-7DA1-3D87-863E-1119F5BB0CF9}</Project>
      <Name>ggml</Name>
    </ProjectReference>
    <ProjectReference Include="D:\git3\MagicLeap\LLM\dd\llama.cpp\build\src\llama.vcxproj">
      <Project>{0CE169F5-A016-3198-964E-18879AC356D8}</Project>
      <Name>llama</Name>
    </ProjectReference>
  </ItemGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
    <Import Project="$(VCTargetsPath)\BuildCustomizations\CUDA 12.6.targets" />
  </ImportGroup>
</Project>