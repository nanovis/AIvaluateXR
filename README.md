# **LoXR: LLM Deployment & Performance Evaluation on XR Devices**  
![Teaser](images/LoXR.jpg)

**LoXR** is a framework for deploying and benchmarking **Large Language Models (LLMs) on XR devices**. Built upon `llama.cpp`, it extends functionality to **four XR devices**:  

- 🥽 **Apple Vision Pro**  
- 🪄 **Magic Leap 2**  
- 📱 **Vivo X100 Pro**  
- 🎮 **Meta Quest 3**  

## 🚀 **Features**  

LoXR provides **custom scripts** for comprehensive performance evaluation, including:  

✅ **Prompt Processing Time** – Measures the efficiency of input processing.  
✅ **Token Generation Speed** – Evaluates LLM inference speed in tokens per second.  
✅ **Batch & Thread Performance** – Analyzes the impact of batch sizes and thread configurations.  
✅ **Battery & Memory Consumption Analysis** – Tracks resource utilization on XR devices.  

## 🛠️ **Installation**  

To use LoXR, clone the repository and install dependencies:  

```bash
git clone https://github.com/yourusername/LoXR.git
cd LoXR


## Publications

  Dawar Khan, Liu, Xinyu and Mena, Omar and Jia, Donggang and Kouyoumdjian, Alexandre and Viola, Ivan, <i>"LoXR: Performance Evaluation of Locally Executing LLMs on XR Devices"</i>, [arxiv.org preprint](https://arxiv.org/tba).

If you find our work useful, please consider citing our paper:
```bibtex


@article{LoXR2025,
  title        = {LoXR: Performance Evaluation of Locally Executing LLMs on XR Devices},
  author       = {Khan, Dawar and Liu, Xinyu and Mena, Omar and Jia, Donggang and Kouyoumdjian, Alexandre and Viola, Ivan},
  year         = 2025,
  journal      = {arxiv.org preprint },
}

@article{LoXR2025b,
  title        = {LLMs on XR (LoXR): Performance Evaluation of LLMs Executed Locally on Extended Reality Devices},
  author       = {Liu, Xinyu and Khan, Dawar and  Mena, Omar and Jia, Donggang and Kouyoumdjian, Alexandre and Viola, Ivan},
  year         = 2025,
  journal      = {IEEE VR 2025 Posters (accepted)},
}
