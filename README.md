# **LoXR: LLM Deployment & Performance Evaluation on XR Devices**  
![Teaser](images/LoXR.jpg)

**LoXR** is a framework for deploying and benchmarking **Large Language Models (LLMs) on XR devices**. Built upon `llama.cpp`, it extends functionality to **four XR devices**:  

- ğŸ¥½ **Apple Vision Pro**  
- ğŸª„ **Magic Leap 2**  
- ğŸ“± **Vivo X100 Pro**  
- ğŸ® **Meta Quest 3**  

## ğŸš€ **Features**  

LoXR provides **custom scripts** for comprehensive performance evaluation, including:  

âœ… **Prompt Processing Time** â€“ Measures the efficiency of input processing.  
âœ… **Token Generation Speed** â€“ Evaluates LLM inference speed in tokens per second.  
âœ… **Batch & Thread Performance** â€“ Analyzes the impact of batch sizes and thread configurations.  
âœ… **Battery & Memory Consumption Analysis** â€“ Tracks resource utilization on XR devices.  

## ğŸ› ï¸ **Installation**  

To use LoXR, clone the repository and install dependencies:  

```bash
git clone https://github.com/yourusername/LoXR.git
cd LoXR


## Publications

  Dawar Khan, Liu, Xinyu and Mena, Omar and Jia, Donggang and Kouyoumdjian, Alexandre and Viola, Ivan, <i>"LoXR: Performance Evaluation of Locally Executing LLMs on XR Devices"</i>, [arxiv.org preprint](https://arxiv.org/tba).

If you find our work useful, please consider citing our paper:
```bibtex


@article{LoXR2025,
  title        = {LoXR: Performance Evaluation of Locally Executing LLMs on XR Devices},
  author       = {Khan, Dawar and Liu, Xinyu and Mena, Omar and Jia, Donggang and Kouyoumdjian, Alexandre and Viola, Ivan},
  year         = 2025,
  journal      = {arxiv.org preprint },
}

@article{LoXR2025b,
  title        = {LLMs on XR (LoXR): Performance Evaluation of LLMs Executed Locally on Extended Reality Devices},
  author       = {Liu, Xinyu and Khan, Dawar and  Mena, Omar and Jia, Donggang and Kouyoumdjian, Alexandre and Viola, Ivan},
  year         = 2025,
  journal      = {IEEE VR 2025 Posters (accepted)},
}
