# **AIvaluateXR: An Evaluation Framework for on-Device AI in XR with Benchmarking Results**  
![Teaser](images/LoXR.jpg)

## ğŸ† **Acknowledgment**
AIvaluateXR is built upon **[`llama.cpp`](https://github.com/ggml-org/llama.cpp)**.  [`llama.cpp`](https://github.com/ggml-org/llama.cpp) is an excellent C++ implementation for running LLMs efficiently on various hardware. 
We deployed **LLMs** locally on **XR devices** by customizing the **[`llama.cpp`](https://github.com/ggml-org/llama.cpp)** for four different XR devices. 

## ğŸš€ **Overview**  

**AIvaluateXR** is a framework for deploying and benchmarking **Large Language Models (LLMs) on XR devices**. It enables **on-device execution** of LLMs and provides tools for **performance analysis** across different XR platforms including:  

-  **Apple Vision Pro**  
-  **Magic Leap 2**  
- **Vivo X100 Pro**  
-  **Meta Quest 3**  

---


## ğŸ¥ **LoXR Video Demo**
[AIvaluateXR Video](https://youtu.be/7TrXLekrEyI)  
 ---

## ğŸ”¥ Script for the the Key Tests, including:  

âœ… **Prompt Processing Test** â€“ Measures the efficiency of input processing.  
âœ… **Token Generation Test** â€“ Evaluates LLM inference speed in tokens per second.  
âœ… **Batch Test & Thread Test** â€“ Analyzes the impact of batch sizes and thread configurations.  
âœ… **Battery & Memory Consumption Analysis** â€“ Tracks resource utilization on XR devices.  

---





## ğŸ› ï¸ **Installation**  

Clone the repository and install dependencies:

```bash
git clone https://github.com/nanovis/AIvaluateXR.git
cd AIvaluateXR


#pareto analysis
python scripts/pareto.py --csv metrics.csv
```


## ğŸ› ï¸ **How to use it**  
For detailed workflow instructions, see [Workflow Documentation](docs/workflow.md).




## ğŸ“‚ Project Directory Structure

Below is the recommended directory layout for **AIvaluateXR**:

```
AIvaluateXR/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ workflow.md
â”œâ”€â”€ images/
â”‚   â””â”€â”€ (images for documentation)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ Android_devices/
â”‚   â”‚   â”œâ”€â”€ battery_test/
â”‚   â”‚   â”œâ”€â”€ memory_test/
â”‚   â”‚   â”œâ”€â”€ speed_and_consistency_test/
â”‚   â”‚   â””â”€â”€ android_readme.md     # âœ… Shows how to use LLMs on ML2, MQ3, and Vivoo X100 Pro 
â”‚   â”‚
â”‚   â”œâ”€â”€ AVP/
â”‚   â”‚   â”œâ”€â”€ battery_test/
â”‚   â”‚   â”œâ”€â”€ memory_test/
â”‚   â”‚   â”œâ”€â”€ speed_and_consistency_test/
â”‚   â”‚   â””â”€â”€ avp_readme.md         # âœ… hows how to use LLMs on AVP 
â”‚   â”‚
â”‚   â”œâ”€â”€ quality/
â”‚   â”‚   â””â”€â”€ datasets/
â”‚   â”‚
â”‚   â”œâ”€â”€ merge_metrics.py
â”‚   â””â”€â”€ pareto.py
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt              # 

```

---

## ğŸ“˜ Additional Resources 
- [Llama.cpp Repository](https://github.com/ggerganov/llama.cpp)
- [Paper (arXiv)](https://arxiv.org/abs/2502.15761)
- [Paper (IEEE VR Poster)](https://ieeexplore.ieee.org/abstract/document/10973004)
- [Project Website](https://www.nanovis.org/AIvaluateXR.html)


## Publications

  Dawar Khan, Xinyu Liu, Omar Mena, Donggang Jia, Alexandre Kouyoumdjian, Ivan Viola,
"LoXR: Performance Evaluation of Locally Executing LLMs on XR Devices",
arXiv preprint, 2025.

If you find our work useful, please consider citing our paper:
```bibtex


@article{LoXR2025ArXiv,
  title        = {LoXR: Performance Evaluation of Locally Executing LLMs on XR Devices},
  author       = {Khan, Dawar and Liu, Xinyu and Mena, Omar and Jia, Donggang and Kouyoumdjian, Alexandre and Viola, Ivan},
  year         = 2025,
  journal      = {arxiv.org preprint },
}

@INPROCEEDINGS{LoXR:2025IEEVR,
  author={Liu, Xinyu and Khan, Dawar and Mena, Omar and Jia, Donggang and Kouyoumdjian, Alexandre and Viola, Ivan},
  booktitle={2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={LLMs on XR (LoXR): Performance Evaluation of LLMs Executed Locally on Extended Reality Devices}, 
  year={2025},
  volume={},
  number={},
  pages={1212-1213}, 
  doi={10.1109/VRW66409.2025.00252}}

